{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvCk8emQUFqk"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZd3vqGgUFqm"
      },
      "source": [
        "# Data Ethics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ1m-vmRUFqo"
      },
      "source": [
        "### Sidebar: Acknowledgement: Dr. Rachel Thomas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvwGDwhiUFqp"
      },
      "source": [
        "### End sidebar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN1ht5-GUFqp"
      },
      "source": [
        "## Key Examples for Data Ethics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LfpuzD3UFqq"
      },
      "source": [
        "### Bugs and Recourse: Buggy Algorithm Used for Healthcare Benefits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3hgOBXCUFqq"
      },
      "source": [
        "### Feedback Loops: YouTube's Recommendation System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B70qUNvgUFqs"
      },
      "source": [
        "### Bias: Professor Latanya Sweeney \"Arrested\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Hr1-xg6UFqu"
      },
      "source": [
        "### Why Does This Matter?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6ciCwSVUFqv"
      },
      "source": [
        "## Integrating Machine Learning with Product Design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqnEaB7oUFqw"
      },
      "source": [
        "## Topics in Data Ethics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARXkY3CWUFqw"
      },
      "source": [
        "### Recourse and Accountability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeDE7L2oUFqw"
      },
      "source": [
        "### Feedback Loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6gpG6yZUFqx"
      },
      "source": [
        "### Bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD0BA4JmUFqx"
      },
      "source": [
        "#### Historical bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsj3Q_AAUFqx"
      },
      "source": [
        "#### Measurement bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JXONxL8UFqx"
      },
      "source": [
        "#### Aggregation bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15FsL7_jUFqy"
      },
      "source": [
        "#### Representation bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8waC1HZUFqz"
      },
      "source": [
        "### Addressing different types of bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NghS3DLUFq0"
      },
      "source": [
        "### Disinformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtWZWXcjUFq0"
      },
      "source": [
        "## Identifying and Addressing Ethical Issues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERr3uDvDUFq0"
      },
      "source": [
        "### Analyze a Project You Are Working On"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMDI29CFUFq1"
      },
      "source": [
        "### Processes to Implement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muBsQ5CjUFq1"
      },
      "source": [
        "#### Ethical lenses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1vr8vWFUFq1"
      },
      "source": [
        "### The Power of Diversity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoypCVqQUFq2"
      },
      "source": [
        "### Fairness, Accountability, and Transparency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sk_CBxYUFq2"
      },
      "source": [
        "## Role of Policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ODrH8FkUFq2"
      },
      "source": [
        "### The Effectiveness of Regulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKS_p_KFUFq2"
      },
      "source": [
        "### Rights and Policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-kHh0CJUFq2"
      },
      "source": [
        "### Cars: A Historical Precedent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYlV0EDTUFq2"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r6lXU3RUFq3"
      },
      "source": [
        "## Questionnaire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASnvUwP4UFq3"
      },
      "source": [
        "1. Does ethics provide a list of \"right answers\"?\n",
        "\n",
        "  No.\n",
        "\n",
        "  \"Ethics is **not** the same as religion, law, social norms, or feelings\n",
        "  Ethics is **not** a fixed set of rules\n",
        "\n",
        "  Ethics is:\n",
        "  1. well-founded standards of right and wrong that prescribe what humans ought to do\n",
        "  2. the study and development of one's ethical standards\"\n",
        "\n",
        "1. How can working with people of different backgrounds help when considering ethical questions?\n",
        "\n",
        "  \"Spotting ethical issues is best to do as part of a collaborative team. This is the only way you can really incorporate different perspectives. Different people's backgrounds will help them to see things which may not be obvious to you. Working with a team is helpful for many \"muscle-building\" activities, including this one.\"\n",
        "\n",
        "1. What was the role of IBM in Nazi Germany? Why did the company participate as it did? Why did the workers participate?\n",
        "\n",
        "  IBM produced computers used in concentration camps things like whether or not they were Jewish, when they were executed, etc.  IBM kept ties long after many companies had stopped supporting the Nazis.  The machines required a lot of maintenence and required an ongoing relationship with vendors as a result.\n",
        "\n",
        "1. What was the role of the first person jailed in the Volkswagen diesel scandal?\n",
        "\n",
        "  Volkswagen was cheating on emissions tests.  It was a programmer who was just following the direction from their boss.  Not an excuse when performing unethical behavior.\n",
        "\n",
        "1. What was the problem with a database of suspected gang members maintained by California law enforcement officials?\n",
        "\n",
        "  Auditor found 42 babies < 1 year old at the time were entered into the database.  28 of those were marked as \"admitting to being gang members\".  People never removed once added.\n",
        "\n",
        "1. Why did YouTube's recommendation algorithm recommend videos of partially clothed children to pedophiles, even though no employee at Google had programmed this feature?\n",
        "\n",
        "  \"Feedback loops can occur when **your model is controlling the next round of data you get**.  The data that is returned quickly becomes flawed by the software itself.\"\n",
        "\n",
        "1. What are the problems with the centrality of metrics?\n",
        "\n",
        "  \"Much of AI/ML centers on optimizing a metric.  Overemphasizing metrics leads to:\n",
        "  - manipulation\n",
        "  - gaming\n",
        "  - myopic focus on short-term goals\n",
        "  - unexpected negative consequences\"\n",
        "\n",
        "  Related paper: \"Reliance on Metrics is a Fundamental Challenge\", Rachel Thomas and David Uminsky\n",
        "\n",
        "  Examples where overoptimizing metrics (especially the wrong ones) led to unintended consequences:\n",
        "  - UK public health\n",
        "  - grading students' essays\n",
        "\n",
        "  Goodhart's law - \"When a measure becomes a target, it ceases to be a good measure\"\n",
        "\n",
        "1. Why did Meetup.com not include gender in its recommendation system for tech meetups?\n",
        "\n",
        "  Men were found to tend to take more interest in tech meetups on their platform.  If gender were to be included then this would likely cause the system to recommend less tech meetups to their female members causing less female members to find out about the event and having less attend.  This change would then cause a feedback loop continuously driving fewer and fewer female members to find out and ultimately attend tech-related meetups.\n",
        "\n",
        "1. What are the six types of bias in machine learning, according to Suresh and Guttag?\n",
        "\n",
        "  1. Representation bias\n",
        "  1. Evaluation \n",
        "  1. Machine bias\n",
        "  1. Historical bias\n",
        "  1. Measurement bias\n",
        "  1. Racial bias\n",
        "\n",
        "  Sources:\n",
        "  - The Problem with \"Biased Data\", Harini Suresh\n",
        "  - A Framework for Understanding Unintended Consequences of Machine Learning, Harini Suresh and John V. Guttag\n",
        "\n",
        "1. Give two examples of historical race bias in the US.\n",
        "\n",
        "  \"Historical bias is a fundamental, structural issue with the first step of the data generation process and can exist even given perfect sampling and feature selection.\" - Suresh et. al. 2019\n",
        "\n",
        "  - algorithms used to predict recidivism used in prison sentencing (many more false positives for black defendants)\n",
        "  - \"doctors shown identical files much less likely to recommend cardiac catheteriszation (in helpful situation) to black patients\"\n",
        "  - \"when bargaining for a used car, black people were offered initial prices $700 higher and received far smaller concessions.\"\n",
        "  - \"Responding to apartment-rental ads on Craigslist with a black name elicited fewer responses than with a white name.\"\n",
        "  - \"An all-white jury was 16 points more likely to convict a black defendant than a white one, but when a jury had 1 black member, it convicted both at the same rate.\"\n",
        "\n",
        "1. Where are most images in ImageNet from?\n",
        "\n",
        "  - 45.4% are from the US\n",
        "  - 7.5% from GB\n",
        "  - 6.2% from IT\n",
        "  - 3% from CAN ...\n",
        "\n",
        "  2/3 of ImageNet images from the West (Shankar et al, 2017)\n",
        "\n",
        "1. In the paper [\"Does Machine Learning Automate Moral Hazard and Error\"](https://scholar.harvard.edu/files/sendhil/files/aer.p20171084.pdf) why is sinusitis found to be predictive of a stroke?\n",
        "\n",
        "  People who use healthcare a lot will go in when they have sinusitis and when they are having a stroke.  Those who don't may not go in for either.\n",
        "\n",
        "  They haven't measured \"stroke\".  Instead htey measured: have symptoms, go to doctor, get tests, AND receive diagnosis of stroke.\n",
        "\n",
        "  Example of **measurement bias**\n",
        "\n",
        "1. What is representation bias?\n",
        "\n",
        "  Representation bias is concerned with biases introduced when a given population is defined and sampled to produce the dataset used to train the model.\n",
        "\n",
        "  Joy Buolamwini & Timnit Gebru ([gendershades.org](gendershades.org)) performed work analyzing products from major companies (Microsoft, IBM, etc) finding that systems performed much better for white males vs. darker females (for example).  Could build a more representative dataset (with consent) to help ameliorate this issue.  For example, IJB-A, a benchmark dataset at the time, contained only 4.4% of their images depicting dark-skinned women.\n",
        "\n",
        "1. How are machines and people different, in terms of their use for making decisions?\n",
        "\n",
        "  - \"People are more likely to assume algorithms are **objective or error-free** (even if they're given the option of a human override)\"\n",
        "  - \"Algorithms are more likely to be implemented with **no appeals process** in place.\"\n",
        "  - \"Algorithms are often used **at scale**.\"\n",
        "  - \"Algorithmic systems are **cheap**.\"\n",
        "\n",
        "  Weapons of Math Desctruction - Cathy O'Neil\n",
        "\n",
        "1. Is disinformation the same as \"fake news\"?\n",
        "\n",
        "  Disinformation includes orchestrated campaigns of manipulation.\n",
        "\n",
        "1. Why is disinformation through auto-generated text a particularly significant issue?\n",
        "\n",
        "  Online discussion will be swamped with fake, manipulative agents and can be used to influence public opinion.\n",
        "\n",
        "  \"We have the technology to totally fill Twitter, email, and teh web up with reasonable-sounding context-appropriate prose, which would drown out all other speech and be impossible to filter.\" - Jeremy Howard\n",
        "\n",
        "1. What are the five ethical lenses described by the Markkula Center?\n",
        "\n",
        "  1. The Rights Approach: Which option best respects the rights of all who have a stake?\n",
        "  1. The Justice Approach: Which option treats people equally or proportionately?\n",
        "  1. The Utilitatian Approach: Which option will produce the most good and do the least harm?\n",
        "  1. The Common Good Approach: Which option best serves the community as a whole, not just some mebers?\n",
        "  1. The Virtue Approach: Which option leads me to act as the sort of person I want to be?\n",
        "\n",
        "1. Where is policy an appropriate tool for addressing data ethics issues?\n",
        "\n",
        "  \" We need policy AND ethical industry behavior\n",
        "\n",
        "  - Policy is the appropriate tool for addressing:\n",
        "    - negative externalities\n",
        "    - misaligned economic incentives\n",
        "    - \"race to the bottom\" situations\n",
        "    - enforcing accountability\n",
        "  - Ethical behavior in industry is necessary as well, since:\n",
        "    - Law will not always keep up\n",
        "    - Edge cases arise\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phhJCe49UFq3"
      },
      "source": [
        "### Further Research:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJRn8AfUUFq4"
      },
      "source": [
        "1. Read the article \"What Happens When an Algorithm Cuts Your Healthcare\". How could problems like this be avoided in the future?\n",
        "1. Research to find out more about YouTube's recommendation system and its societal impacts. Do you think recommendation systems must always have feedback loops with negative results? What approaches could Google take to avoid them? What about the government?\n",
        "1. Read the paper [\"Discrimination in Online Ad Delivery\"](https://arxiv.org/abs/1301.6822). Do you think Google should be considered responsible for what happened to Dr. Sweeney? What would be an appropriate response?\n",
        "1. How can a cross-disciplinary team help avoid negative consequences?\n",
        "1. Read the paper \"Does Machine Learning Automate Moral Hazard and Error\". What actions do you think should be taken to deal with the issues identified in this paper?\n",
        "1. Read the article \"How Will We Prevent AI-Based Forgery?\" Do you think Etzioni's proposed approach could work? Why?\n",
        "1. Complete the section \"Analyze a Project You Are Working On\" in this chapter.\n",
        "1. Consider whether your team could be more diverse. If so, what approaches might help?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXIXK-GgUFq4"
      },
      "source": [
        "## Deep Learning in Practice: That's a Wrap!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUIBabxXUFq4"
      },
      "source": [
        "Congratulations! You've made it to the end of the first section of the book. In this section we've tried to show you what deep learning can do, and how you can use it to create real applications and products. At this point, you will get a lot more out of the book if you spend some time trying out what you've learned. Perhaps you have already been doing this as you go along—in which case, great! If not, that's no problem either... Now is a great time to start experimenting yourself.\n",
        "\n",
        "If you haven't been to the [book's website](https://book.fast.ai) yet, head over there now. It's really important that you get yourself set up to run the notebooks. Becoming an effective deep learning practitioner is all about practice, so you need to be training models. So, please go get the notebooks running now if you haven't already! And also have a look on the website for any important updates or notices; deep learning changes fast, and we can't change the words that are printed in this book, so the website is where you need to look to ensure you have the most up-to-date information.\n",
        "\n",
        "Make sure that you have completed the following steps:\n",
        "\n",
        "- Connect to one of the GPU Jupyter servers recommended on the book's website.\n",
        "- Run the first notebook yourself.\n",
        "- Upload an image that you find in the first notebook; then try a few different images of different kinds to see what happens.\n",
        "- Run the second notebook, collecting your own dataset based on image search queries that you come up with.\n",
        "- Think about how you can use deep learning to help you with your own projects, including what kinds of data you could use, what kinds of problems may come up, and how you might be able to mitigate these issues in practice.\n",
        "\n",
        "In the next section of the book you will learn about how and why deep learning works, instead of just seeing how you can use it in practice. Understanding the how and why is important for both practitioners and researchers, because in this fairly new field nearly every project requires some level of customization and debugging. The better you understand the foundations of deep learning, the better your models will be. These foundations are less important for executives, product managers, and so forth (although still useful, so feel free to keep reading!), but they are critical for anybody who is actually training and deploying models themselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aorPMvxtUFrC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "split_at_heading": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "03_ethics.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}